# Vocalis backend configuration

# API Endpoints
LLM_API_ENDPOINT=http://127.0.0.1:1234/v1/chat/completions  # Place your local LLM API endpoint here (default is LM Studio)
TTS_API_ENDPOINT=http://localhost:5005/v1/audio/speech  # Place your local TTS API endpoint here (default is Orpheus-FASTAPI native python launcher) - If you're using Orpheus-FASTAPI Docker Container versus native python launcher, replace "localhost" with "127.0.0.1:5005"

# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here  # Your OpenAI API key for using OpenAI Agent SDK
OPENAI_MODEL=gpt-4o-mini  # OpenAI model to use (gpt-4o, gpt-4-turbo, gpt-3.5-turbo, etc.)
OPENAI_TTS_VOICE=alloy  # OpenAI TTS voice (alloy, echo, fable, onyx, nova, shimmer)
OPENAI_TTS_MODEL=tts-1  # OpenAI TTS model (tts-1, tts-1-hd)
USE_OPENAI=true  # Set to true to use OpenAI Agent SDK instead of local AI

# Whisper Model Configuration
WHISPER_MODEL=base  # Options: tiny.en, base.en, small.en, medium.en, large

# TTS Configuration
TTS_MODEL=tts-1 
TTS_VOICE=tara 
TTS_FORMAT=wav        # Format for TTS output (wav, mp3, opus, flac)

# WebSocket Server Configuration
WEBSOCKET_HOST=0.0.0.0
WEBSOCKET_PORT=8000

# Audio Processing
VAD_THRESHOLD=0.1          # Voice activity detection threshold (0.0-1.0)
VAD_BUFFER_SIZE=30         # Buffer size in milliseconds
AUDIO_SAMPLE_RATE=44100    # Sample rate in Hz
